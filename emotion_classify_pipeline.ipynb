{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3afe4a1-5eba-464c-a113-552cf0368a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up environment for the pipeline\n",
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "REGION = \"asia-south1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb59307f-9cde-470a-bff4-037100b926c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2cc8989-477a-42ff-b7cf-b8ad23a0528f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcs://emotion-classify-bucket/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing clients \n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "\n",
    "# initializing bucket\n",
    "BUCKET = \"gcs://emotion-classify-bucket/\"\n",
    "BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068ee52f-2f0b-4c58-9af0-933674b05cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1181571513-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Services and accoung permissions\n",
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)'\n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11acfbdf-74b7-4349-af03-fc6892d2ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Cloud resource manager API\n",
    "!gcloud services enable cloudresourcemanager.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e45ae8-8e49-4842-bafa-acb58a955e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "['roles/aiplatform.customCodeServiceAgent', 'roles/aiplatform.serviceAgent', 'roles/artifactregistry.serviceAgent', 'roles/bigquery.admin', 'roles/cloudbuild.builds.builder', 'roles/cloudbuild.serviceAgent', 'roles/cloudfunctions.serviceAgent', 'roles/composer.serviceAgent', 'roles/compute.serviceAgent', 'roles/container.serviceAgent', 'roles/containerregistry.ServiceAgent', 'roles/dataflow.serviceAgent', 'roles/editor', 'roles/notebooks.serviceAgent', 'roles/owner', 'roles/pubsub.serviceAgent', 'roles/run.admin', 'roles/run.serviceAgent', 'roles/storage.admin', 'roles/storage.objectAdmin']\n"
     ]
    }
   ],
   "source": [
    "# Listing the current service account roles:\n",
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" \\\n",
    "    --format='table(bindings.role)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ba75e6-24af-4dc5-9c9b-2aa8972599a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kubeflow and cloud components\n",
    "!pip install kfp -U -q\n",
    "!pip install google-cloud-pipeline-components -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30a7ae6-cfee-4d05-91c0-b1c46b6f59f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kfp\n",
    "KFP_version = kfp.__version__\n",
    "KFP_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c4e9520-2ed7-4d50-b630-9d367be71b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google_cloud_pipeline_components\n",
    "google_cloud_pipeline_components_version = google_cloud_pipeline_components.__version__\n",
    "google_cloud_pipeline_components_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b731466-de04-42e0-a807-cfb67ca29ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.33.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b33f4c2-2995-4ead-bd7e-5f9d04c41f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcs://emotion-classify-bucket/Emotion_classify_Data.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use data from BigQuery table to train the model and create pipeline\n",
    "EXPERIMENT = \"emotion\"\n",
    "SERIES = \"emotion_01\"\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = \"emotion\"\n",
    "BQ_TABLE = \"emotion\"\n",
    "\n",
    "# sourcing data from gcs bucket\n",
    "BQ_SOURCE = BUCKET + \"Emotion_classify_Data.csv\"\n",
    "BQ_SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d7c46f-8c13-4a77-8fe9-3c72b394b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-pipeline-project-401216.emotion already exists\n"
     ]
    }
   ],
   "source": [
    "# create dataset in bigquery\n",
    "dataset_id = \"{}.{}\".format(BQ_PROJECT,BQ_DATASET)\n",
    "\n",
    "try:\n",
    "    bq.get_dataset(dataset_id)\n",
    "    print(\"Dataset {} already exists\".format(dataset_id))\n",
    "except NotFound:\n",
    "    client = bigquery.Client()\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = REGION\n",
    "    dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "    print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "617386a2-2a3d-4003-8b3a-9d148406e97f",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ml-pipeline-project-401216/jobs?prettyPrint=false: Source URI must be a Google Cloud Storage location: gcs://emotion-classify-bucket/Emotion_classify_Data.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m job_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mLoadJobConfig(\n\u001b[1;32m      3\u001b[0m     schema \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m         bigquery\u001b[38;5;241m.\u001b[39mSchemaField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTRING\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#source_format=bigquery.SourceFormat.CSV,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(PROJECT_ID, BQ_DATASET, BQ_TABLE)\n\u001b[0;32m---> 14\u001b[0m load_job \u001b[38;5;241m=\u001b[39m \u001b[43mbq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBQ_SOURCE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Make an API request.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m load_job\u001b[38;5;241m.\u001b[39mresult()  \u001b[38;5;66;03m# Waits for the job to complete.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# destination_table = client.get_table(table_id)  # Make an API request.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(\"Loaded {} rows.\".format(destination_table.num_rows))\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:2380\u001b[0m, in \u001b[0;36mClient.load_table_from_uri\u001b[0;34m(self, source_uris, destination, job_id, job_id_prefix, location, project, job_config, retry, timeout)\u001b[0m\n\u001b[1;32m   2377\u001b[0m new_job_config \u001b[38;5;241m=\u001b[39m job_config\u001b[38;5;241m.\u001b[39m_fill_from_default(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_load_job_config)\n\u001b[1;32m   2379\u001b[0m load_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mLoadJob(job_ref, source_uris, destination, \u001b[38;5;28mself\u001b[39m, new_job_config)\n\u001b[0;32m-> 2380\u001b[0m \u001b[43mload_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_job\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m--> 693\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.job.begin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_api_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:816\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    814\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    815\u001b[0m     ):\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ml-pipeline-project-401216/jobs?prettyPrint=false: Source URI must be a Google Cloud Storage location: gcs://emotion-classify-bucket/Emotion_classify_Data.csv"
     ]
    }
   ],
   "source": [
    "# creating table in bigquery from data in gcs bucket\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"Comment\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"Emotion\", \"STRING\"),\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    #source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "\n",
    "table_id = \"{}.{}.{}\".format(PROJECT_ID, BQ_DATASET, BQ_TABLE)\n",
    "\n",
    "load_job = bq.load_table_from_uri(\n",
    "    BQ_SOURCE, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "# destination_table = client.get_table(table_id)  # Make an API request.\n",
    "# print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bfbb340-d1e2-49c0-b11e-fa89ec7da876",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ml-pipeline-project-401216/jobs?prettyPrint=false: Source URI must be a Google Cloud Storage location: gcs://emotion-classify-bucket/Emotion_classify_Data.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m uri \u001b[38;5;241m=\u001b[39m BQ_SOURCE\n\u001b[1;32m     17\u001b[0m table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(PROJECT_ID, BQ_DATASET, BQ_TABLE)\n\u001b[0;32m---> 19\u001b[0m load_job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Make an API request.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m load_job\u001b[38;5;241m.\u001b[39mresult()  \u001b[38;5;66;03m# Waits for the job to complete.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m destination_table \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_table(table_id)  \u001b[38;5;66;03m# Make an API request.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:2380\u001b[0m, in \u001b[0;36mClient.load_table_from_uri\u001b[0;34m(self, source_uris, destination, job_id, job_id_prefix, location, project, job_config, retry, timeout)\u001b[0m\n\u001b[1;32m   2377\u001b[0m new_job_config \u001b[38;5;241m=\u001b[39m job_config\u001b[38;5;241m.\u001b[39m_fill_from_default(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_load_job_config)\n\u001b[1;32m   2379\u001b[0m load_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mLoadJob(job_ref, source_uris, destination, \u001b[38;5;28mself\u001b[39m, new_job_config)\n\u001b[0;32m-> 2380\u001b[0m \u001b[43mload_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m load_job\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/base.py:693\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m--> 693\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.job.begin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_api_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:816\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    814\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    815\u001b[0m     ):\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 POST https://bigquery.googleapis.com/bigquery/v2/projects/ml-pipeline-project-401216/jobs?prettyPrint=false: Source URI must be a Google Cloud Storage location: gcs://emotion-classify-bucket/Emotion_classify_Data.csv"
     ]
    }
   ],
   "source": [
    "# Construct a BigQuery client object.\n",
    "client = bigquery.Client(project = PROJECT_ID)\n",
    "\n",
    "# TODO(developer): Set table_id to the ID of the table to create.\n",
    "# table_id = \"your-project.your_dataset.your_table_name\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"name\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"post_abbr\", \"STRING\"),\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    ")\n",
    "uri = BQ_SOURCE\n",
    "table_id = \"{}.{}.{}\".format(PROJECT_ID, BQ_DATASET, BQ_TABLE)\n",
    "\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "destination_table = client.get_table(table_id)  # Make an API request.\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681edc4-0aca-4d37-9bd8-8d3005e5451d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
